{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import re\n",
    "import requests\n",
    "import urllib.request\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_links(url):\n",
    "\n",
    "    scroll_pause_time = 1\n",
    "    driver = webdriver.Chrome(executable_path=r\"C:\\Users\\nulad\\Desktop\\НИРС\\2семестр\\gnuwget\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    #measure scroll height\n",
    "\n",
    "    last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0,document.documentElement.scrollHeight);\")\n",
    "\n",
    "        # Wait to load page\n",
    "        time.sleep(scroll_pause_time)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "\n",
    "        last_height = new_height\n",
    "\n",
    "    # Get html of the scrolled page\n",
    "    return driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(search_request):\n",
    "    \n",
    "    # Scroll the page and get html \n",
    "    html = scrape_links(search_request)\n",
    "    \n",
    "    # Make a BeautifulSoup object from html\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    # Find needed hrefs in their class\n",
    "    found_urls = soup.find_all(\"h2\", class_=\"title\")\n",
    "    found_years = soup.find_all(\"span\", class_=\"span-block\")\n",
    "    \n",
    "    # Get hrefs from thier class and add them into a list\n",
    "    href_list = []\n",
    "    year_list = []\n",
    "    for i in found_urls:\n",
    "        href_list.append(i.find(\"a\").get('href'))\n",
    "    for i in found_years:\n",
    "        year_list.append(i.text[0:4])\n",
    "    return {\"hrefs\":href_list, \"years\":year_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(site_url, href_list): \n",
    "    # Iterate over a list of hrefs and download articles\n",
    "    for num, href in enumerate(href_list):\n",
    "        \n",
    "        # Concatenate site_url, href and \"/pdf\" to get download link\n",
    "        article_url = site_url + href + \"/pdf\"\n",
    "        \n",
    "        # Download the article\n",
    "        urllib.request.urlretrieve(article_url, r\"C:\\Users\\nulad\\Desktop\\НИРС\\2семестр\\прога\\drop\\{}.pdf\"\n",
    "                                   .format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Site url\n",
    "site = \"https://cyberleninka.ru\"\n",
    "\n",
    "# Search request (\"page=1\" needs to be in the end)\n",
    "my_search_request = \"https://cyberleninka.ru/search?q=%D0%9A%D0%BE%D0%BC%D0%BF%D1%80%D0%B8%D0%BC%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%BD%D1%8B%D0%B9%20%D0%BF%D1%80%D0%B8%D1%80%D0%BE%D0%B4%D0%BD%D1%8B%D0%B9%20%D0%B3%D0%B0%D0%B7&page=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am on page number 1\n",
      "I am on page number 2\n",
      "I am on page number 3\n",
      "I am on page number 4\n",
      "I am on page number 5\n",
      "I am on page number 6\n",
      "I am on page number 7\n",
      "I am on page number 8\n",
      "I am on page number 9\n",
      "I am on page number 10\n",
      "I am on page number 11\n",
      "I am on page number 12\n",
      "I am on page number 13\n",
      "I am on page number 14\n",
      "I am on page number 15\n",
      "I am on page number 16\n",
      "I am on page number 17\n",
      "I am on page number 18\n",
      "I am on page number 19\n",
      "I am on page number 20\n",
      "I am on page number 21\n",
      "I am on page number 22\n",
      "I am on page number 23\n",
      "I am on page number 24\n",
      "I am on page number 25\n",
      "I am on page number 26\n",
      "I am on page number 27\n",
      "I am on page number 28\n",
      "I am on page number 29\n",
      "I am on page number 30\n",
      "I am on page number 31\n",
      "I am on page number 32\n",
      "I am on page number 33\n",
      "I am on page number 34\n",
      "I am on page number 35\n",
      "I am on page number 36\n",
      "I am on page number 37\n",
      "I am on page number 38\n",
      "I am on page number 39\n",
      "I am on page number 40\n",
      "I am on page number 41\n",
      "I am on page number 42\n",
      "I am on page number 43\n",
      "I am on page number 44\n",
      "I am on page number 45\n",
      "I am on page number 46\n",
      "I am on page number 47\n",
      "I am on page number 48\n",
      "I am on page number 49\n",
      "I am on page number 50\n",
      "I am on page number 51\n",
      "I am on page number 52\n",
      "I am on page number 53\n",
      "I am on page number 54\n",
      "I am on page number 55\n",
      "I am on page number 56\n",
      "I am on page number 57\n",
      "I am on page number 58\n",
      "I am on page number 59\n",
      "I am on page number 60\n",
      "I am on page number 61\n",
      "I am on page number 62\n",
      "I am on page number 63\n",
      "I am on page number 64\n",
      "I am on page number 65\n",
      "I am on page number 66\n",
      "I am on page number 67\n",
      "I am on page number 68\n",
      "I am on page number 69\n",
      "I am on page number 70\n",
      "I am on page number 71\n",
      "I am on page number 72\n",
      "I am on page number 73\n",
      "I am on page number 74\n",
      "I am on page number 75\n",
      "I am on page number 76\n",
      "I am on page number 77\n",
      "I am on page number 78\n",
      "I am on page number 79\n",
      "I am on page number 80\n",
      "I am on page number 81\n",
      "I am on page number 82\n",
      "I am on page number 83\n",
      "I am on page number 84\n",
      "I am on page number 85\n",
      "I am on page number 86\n",
      "I am on page number 87\n",
      "I am on page number 88\n",
      "I am on page number 89\n",
      "I am on page number 90\n",
      "I am on page number 91\n",
      "I am on page number 92\n",
      "I am on page number 93\n",
      "I am on page number 94\n",
      "I am on page number 95\n",
      "I am on page number 96\n"
     ]
    }
   ],
   "source": [
    "hrefs = []\n",
    "years = []\n",
    "for i in range(96): # range() contains the number of pages\n",
    "    \n",
    "    my_search_request = my_search_request[:my_search_request.rfind('=')+1] + str(i+1)\n",
    "    \n",
    "    print(\"I am on page number \" + str(i+1))\n",
    "    data = parser(my_search_request)\n",
    "    hrefs += data[\"hrefs\"]\n",
    "    years += data[\"years\"]\n",
    "    \n",
    "download_files(site, hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\nulad\\Desktop\\НИРС\\2семестр\\прога\\years.txt\"\n",
    "with open(file, 'w', encoding='utf-8') as f:\n",
    "    for year in years:\n",
    "        f.write(year + \" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
